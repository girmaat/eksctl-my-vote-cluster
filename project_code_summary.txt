1. .vscode/extensions.json

{
    "recommendations": [
      "hashicorp.terraform",           // Official Terraform extension for syntax and validation
      "editorconfig.editorconfig",     // Enforces consistent code formatting
      "esbenp.prettier-vscode",        // Formatter, helpful when using JSON/YAML in IaC
      "gruntfuggly.todo-tree",         // Highlights TODOs in comments
      "ms-azuretools.vscode-docker",   // Optional, for containerizing later
      "github.vscode-pull-request-github", // GitHub integration for PR reviews
      "amazonwebservices.aws-toolkit-vscode" // Optional: browse AWS resources from VSCode
    ]
  }
  


2. .vscode/settings.json

{
  // Format on save (for Terraform, JSON, YAML, etc.)
  "editor.formatOnSave": true,
  "files.autoSave": "afterDelay",
  "files.autoSaveDelay": 1000,
  // Terraform-specific config
  "[terraform]": {
    "editor.defaultFormatter": "hashicorp.terraform",
    "editor.formatOnSave": true
  },
  // Trim whitespace automatically
  "files.trimTrailingWhitespace": true,
  "files.insertFinalNewline": true,
  // Enable prettier for supported formats
  "[json]": {
    "editor.defaultFormatter": "esbenp.prettier-vscode"
  },
  "[yaml]": {
    "editor.defaultFormatter": "esbenp.prettier-vscode",
    "editor.tabSize": 2
  },
  // Optional: auto-detect indent style via .editorconfig
  "editor.detectIndentation": true
}



3. manifests/db/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: db
spec:
  replicas: 1
  selector:
    matchLabels:
      app: db
  template:
    metadata:
      labels:
        app: db
    spec:
      containers:
        - name: db
          image: postgres:15-alpine
          env:
            - name: POSTGRES_USER
              value: "postgres"
            - name: POSTGRES_PASSWORD
              value: "postgres"
          ports:
            - containerPort: 5432



4. manifests/db/service.yaml

apiVersion: v1
kind: Service
metadata:
  name: db
spec:
  selector:
    app: db
  ports:
    - port: 5432
      targetPort: 5432



5. manifests/worker/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: worker
spec:
  replicas: 1
  selector:
    matchLabels:
      app: worker
  template:
    metadata:
      labels:
        app: worker
    spec:
      containers:
        - name: worker
          image: my-vote-worker:latest



6. manifests/vote/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: vote
spec:
  replicas: 2
  selector:
    matchLabels:
      app: vote
  template:
    metadata:
      labels:
        app: vote
    spec:
      containers:
        - name: vote
          image: my-vote-vote:latest
          ports:
            - containerPort: 80
          env:
            - name: OPTION_A
              value: "Cats"
            - name: OPTION_B
              value: "Dogs"
          readinessProbe:
            httpGet:
              path: /health
              port: 80
            initialDelaySeconds: 5
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 80
            initialDelaySeconds: 15
            periodSeconds: 20



7. manifests/vote/service.yaml

apiVersion: v1
kind: Service
metadata:
  name: vote
spec:
  selector:
    app: vote
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30080
  type: NodePort



8. manifests/redis/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
        - name: redis
          image: redis:alpine
          ports:
            - containerPort: 6379



9. manifests/redis/service.yaml

apiVersion: v1
kind: Service
metadata:
  name: redis
spec:
  selector:
    app: redis
  ports:
    - port: 6379
      targetPort: 6379



10. manifests/result/service.yaml

apiVersion: v1
kind: Service
metadata:
  name: result
spec:
  selector:
    app: result
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30081
  type: NodePort



11. manifests/result/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: result
spec:
  replicas: 2
  selector:
    matchLabels:
      app: result
  template:
    metadata:
      labels:
        app: result
    spec:
      containers:
        - name: result
          image: my-vote-result:latest
          ports:
            - containerPort: 80
          readinessProbe:
            httpGet:
              path: /health
              port: 80
            initialDelaySeconds: 5
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 80
            initialDelaySeconds: 15
            periodSeconds: 20



12. clusters/dev/cluster.yaml

apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: my-vote-cluster
  region: us-east-1
  tags:
    Project: my-vote
    Environment: dev

availabilityZones: ["us-east-1a", "us-east-1b"]

nodeGroups:
  - name: ng-default
    instanceType: t3.medium
    desiredCapacity: 2
    minSize: 1
    maxSize: 3
    volumeSize: 20
    iam:
      withAddonPolicies:
        autoScaler: true
        cloudWatch: true
    tags:
      NodeGroup: default
      Project: my-vote



13. .git/hooks/applypatch-msg.sample

#!/usr/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:



14. .git/hooks/commit-msg.sample

#!/usr/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}



15. .git/hooks/post-update.sample

#!/usr/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info



16. .git/hooks/pre-applypatch.sample

#!/usr/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:



17. .git/hooks/pre-commit.sample

#!/usr/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff-index --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --



18. .git/hooks/pre-merge-commit.sample

#!/usr/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:



19. .git/hooks/pre-push.sample

#!/usr/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0



20. .git/hooks/pre-receive.sample

#!/usr/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi



21. .git/hooks/push-to-checkout.sample

#!/usr/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi



22. .git/hooks/sendemail-validate.sample

#!/usr/bin/sh

# An example hook script to validate a patch (and/or patch series) before
# sending it via email.
#
# The hook should exit with non-zero status after issuing an appropriate
# message if it wants to prevent the email(s) from being sent.
#
# To enable this hook, rename this file to "sendemail-validate".
#
# By default, it will only check that the patch(es) can be applied on top of
# the default upstream branch without conflicts in a secondary worktree. After
# validation (successful or not) of the last patch of a series, the worktree
# will be deleted.
#
# The following config variables can be set to change the default remote and
# remote ref that are used to apply the patches against:
#
#   sendemail.validateRemote (default: origin)
#   sendemail.validateRemoteRef (default: HEAD)
#
# Replace the TODO placeholders with appropriate checks according to your
# needs.

validate_cover_letter () {
	file="$1"
	# TODO: Replace with appropriate checks (e.g. spell checking).
	true
}

validate_patch () {
	file="$1"
	# Ensure that the patch applies without conflicts.
	git am -3 "$file" || return
	# TODO: Replace with appropriate checks for this patch
	# (e.g. checkpatch.pl).
	true
}

validate_series () {
	# TODO: Replace with appropriate checks for the whole series
	# (e.g. quick build, coding style checks, etc.).
	true
}

# main -------------------------------------------------------------------------

if test "$GIT_SENDEMAIL_FILE_COUNTER" = 1
then
	remote=$(git config --default origin --get sendemail.validateRemote) &&
	ref=$(git config --default HEAD --get sendemail.validateRemoteRef) &&
	worktree=$(mktemp --tmpdir -d sendemail-validate.XXXXXXX) &&
	git worktree add -fd --checkout "$worktree" "refs/remotes/$remote/$ref" &&
	git config --replace-all sendemail.validateWorktree "$worktree"
else
	worktree=$(git config --get sendemail.validateWorktree)
fi || {
	echo "sendemail-validate: error: failed to prepare worktree" >&2
	exit 1
}

unset GIT_DIR GIT_WORK_TREE
cd "$worktree" &&

if grep -q "^diff --git " "$1"
then
	validate_patch "$1"
else
	validate_cover_letter "$1"
fi &&

if test "$GIT_SENDEMAIL_FILE_COUNTER" = "$GIT_SENDEMAIL_FILE_TOTAL"
then
	git config --unset-all sendemail.validateWorktree &&
	trap 'git worktree remove -ff "$worktree"' EXIT &&
	validate_series
fi



23. .git/hooks/update.sample

#!/usr/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0



24. .git/hooks/fsmonitor-watchman.sample

#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}



25. .git/hooks/pre-rebase.sample

#!/usr/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END



26. .git/hooks/prepare-commit-msg.sample

#!/usr/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi



27. .git/info/exclude

# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~



28. .git/description

Unnamed repository; edit this file 'description' to name the repository.



29. .git/refs/heads/main

e6de54733422c66d18859882faa550ce5bf68c6f



30. .git/refs/remotes/origin/main

e6de54733422c66d18859882faa550ce5bf68c6f



31. .git/HEAD

ref: refs/heads/main



32. .git/config

[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
[remote "origin"]
	url = git@github.com:girmaat/eksctl-my-vote-cluster.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main



33. .git/objects/ee/5d15f6dbdecb1229d015aa3ac64337d9e9e399

x¥’OK1Å=÷S{Rh·­¡7AŠ¶‡
"âa6;Ûd“%™Vªøİìö Á[Â¼™y¿—Öp1¾8ùè‡0õ¡Fï â†à´ò(ÔCİ‡ÛÅ|Ö‡§Ëû»>˜üL»2*Y|È“eîÚ˜M@Âšú©\±¥˜ãZü®’a%®Èâ6ûEÑ&0F©¬®±!Ã0ŞU¼LóŸuXçïE×&£§’*\[é¨T§‚l…qÅÆ‡&?4¶6]¿èÔÏ½™À5¼­X(6h™‚³Ak·ÉP,*{È–İòñ ş»HA¦ìĞÎèMÕßÃSök‡…%h‰0Ps×MãƒP™nº;¶9¼FïşÅ‚\“ïg6Ñø’²=dö¼ÅÚşkTÊê¨`±à÷v¾ß¡dóFØ+ö¤pP’`W’ˆ²Uê#äİÿ:>øî¿uú›V®ñ{·Ë¶÷Ùû“îı


34. .git/objects/ab/4bd1148429d5182635cff8ce1eeeacf9e80420

xmPËNÃ@ä¼_aõL
mAB¹¡
qC•Š@qpvİÄtÑ>åëÙl åÀqfìñŒí¸ºYœaÏOä;[íƒŒzÎîbX î;¼{¶ª†µN!’_;»ãVCF¬€EC5˜C5¸H•œ3ï©-)T„!V‹ÌElÃ¸°ñîd<.òÎì5d³ hdk‡g)Ôğ:;:âìN¨™½	a¢{ïR_îT?él[)ÚaÒ±Üa"ZI‡>G«¹!ÅÉMQ`Oj=Ê|´†e¡Û-åé±€ÁÏ	®
œN†&fyY(F35øàØİ*åìÆi–œK”‰ÑSt[‰š|Îá©]RÏe÷G8½àá·èø©Sµ>û°P˜


35. .git/objects/39/52392f345e7a7a54abca175559348a6e230e26

x}RËN#1äì¯hœ¡™ÓJ‹‚„H‘xDnH‘ÇÓ“iâØƒ§GÇı‹ıºı’µ™‰6±§yT¹ªºÜ™qü÷zû£Œì(Su)Dnµ§ŠAÙ\ÃUÃPAĞÎ´×wóÙİ|q>½8›ÈÊ»Ô¼Ğ.ÇEİ¬×ÊoR~f)nOo¦³ùâêäòlÒi´j û‡rMn°FŞÕÇÜ—‘5µÄ¤½à6Cc½Ğîã9GÒ9…¤Êğ¸lŒòÔÖ1ääkpêÍÚ]ÕCQDv
	oª 
ûTŠKé¨¿“Y~vcÁ<•±*‡¤u;‚Ü	€ĞİŠªÎŸ–ÖyÌ!ÛÀ’8 TÄĞ%êUÒ¢<†©c½ò¸Dh›f²†‚Ä?İpI¡ßíx®brV™a'í±
rS†û*‰ºtáw×[
ı×hÚKGï¿4C´'¾Cµâ­ËÿÎ'áÆïí½ıNf0èãaÜÜY¢uÿóûÌÚƒn»àÉ3Z`÷>ïË_'MØ¦


36. .git/objects/d5/5b140135d9ca7334db0d66928772ff72d0d142

xµ•İrÚFÇ{½OqºÑ$Ra>Ü›xÔ!²‡	ÆØt:À!- d‘ˆvEãb?BïrÑ‹Îôİú}„ÕJ3ÄîM®`WgÿçìoÏÇŒÇ3¨×Oß=ûşdF'3O,‰`l–Æ°×lî…œVçfpíö§İæ¥ëĞÕ­½‰%³}
ÉJš¿¦}÷¢}Õuh*læ	i×(¹n^Lß¹¿:´—Ä˜/õÎ°Ù¹)E(!ƒV¿İ»ÖÚ†‰!°È[1 F•Z¤×¦­«›îµS%çÍvg· }×í:/ÆÕFcT=kÔW/È%­wjgSÜé»oK“nt[Åd„‘œ.™°Ä´`Ì_Æx{ ãÈØ*¹{Çq`dì9£¸kl»­{z÷¹ŠH}Ÿ	ñPÆØfaŞşùë‹:X2Íòf/_ZV)£ˆjà-”ÂŸJ…yµ
¸ï¿øKæ|pM ¹IK?¼eœÉ0 ¥l)	çàı&€}0á'ál÷Ô`ÛùÛìgÅí„-”5Ê\ Pÿé$`›“(åüä’E@W—º¨±¯B†œû
)(a\°İÑóc§C‹8b”ÌC‚HêöZ˜³[ŞÂ:`’ÛdÀDƒÀ(28û“%®E	jÃÌùõ’Ñfícœ_¡¡?ÍC5#€v1Étôºğòjèñ”	§tFs¹O)KnÑÁè‡IÛ‚§rJì³´Ô³F`ÿo "¤0™@ß‘ëÆ
º!Z
˜ÇiPÖÔg+/ŒÂh¡Ma½­ƒm`®½À&æ)ì±TË-†Ú"O°áUçæÒ=Î03üÆµŒdö÷	˜:Ú'xÆÉzéEHTÃxê¹ÂœÍe¼aIq@¡Í=åtO‘n»w«úÄ±Ë†> E2õ‚ Á¾Ä¾-ÕfáEqí¥3úíõcIªÂı¿PËËv§éîPZ ÏÌCóÇ
´›—ĞùñDİÿŞâÌ‹ÒuÁµÕÙ%kè­€cS²*€æå©´Åèg?$0ÕZù+¿ÇfêKn?hrã÷Ö¤R¥şµ’Î‚x—v’İS‡—dåûDeBpÚYNn®V^r{Ğ/ÿıûË€+¼lväVè« ùøìy˜zŠ–ó.›pÆVÍµs™A9Îô$ØÎ¨Qîb2±OPÅ¾ÏŸ«Ù qqw§ÿÕÈ¢¥¸’


37. .git/objects/6d/4c309c663a53c0b7cf4a43759ac17034d163db

x5ÊA
Â@…a×sŠw¥¨˜S‚ût&H°	™Ğók«îŞûù¦¹MÆÓMâ][%¬Czi-„»øªYÒ"Á…ƒ)•!¸í©›ä­u™%Gómlö€5şíÇıÎãåºC ØŸ·ùå7Ôb+


38. .git/objects/ec/1ddc8efa58f0aa76800bd5cb0209e118718e6c

x•K
Â0Eg™’—AÄ­Üæ%µĞØÒ»77à]\8i¯uíR“»ô–³ÔiR¡2S‚·Æ[(§@6qÑ‘Ùù ´üî’“©òpÀ¤Â Bƒf›YÏNM˜ÎşÚ›\ÖV.ï¿ñ\*Öí–öúlˆÎR0òªbØ×óŸ7ñAİäy0zfñz½DÁ


39. .git/objects/02/032ecd4bfe877887c944b010e1986db89fcc7d

x+)JMU07e040031QÈMÌÌÓ+IcĞÛo#n)¨³Ú‰çOdì§úYÕZP%e‰E™‰I9©Å u·/qévZx‘]Up.ëÁıukË}½7¡


40. .git/COMMIT_EDITMSG

Infra destroyed



41. .git/logs/HEAD

0000000000000000000000000000000000000000 dc28cf316a5aa9077778a232e72da1d3b2b509ab girmaat <girmaat@gmail.com> 1747852769 +0000	commit (initial): first commit
dc28cf316a5aa9077778a232e72da1d3b2b509ab 0000000000000000000000000000000000000000 girmaat <girmaat@gmail.com> 1747852769 +0000	Branch: renamed refs/heads/main to refs/heads/main
dc28cf316a5aa9077778a232e72da1d3b2b509ab dc28cf316a5aa9077778a232e72da1d3b2b509ab girmaat <girmaat@gmail.com> 1747852769 +0000	Branch: renamed refs/heads/main to refs/heads/main
dc28cf316a5aa9077778a232e72da1d3b2b509ab ec1ddc8efa58f0aa76800bd5cb0209e118718e6c girmaat <girmaat@gmail.com> 1747854173 +0000	commit: yaml updated
ec1ddc8efa58f0aa76800bd5cb0209e118718e6c e6de54733422c66d18859882faa550ce5bf68c6f girmaat <girmaat@gmail.com> 1747869289 +0000	commit: Infra destroyed



42. .git/logs/refs/heads/main

0000000000000000000000000000000000000000 dc28cf316a5aa9077778a232e72da1d3b2b509ab girmaat <girmaat@gmail.com> 1747852769 +0000	commit (initial): first commit
dc28cf316a5aa9077778a232e72da1d3b2b509ab dc28cf316a5aa9077778a232e72da1d3b2b509ab girmaat <girmaat@gmail.com> 1747852769 +0000	Branch: renamed refs/heads/main to refs/heads/main
dc28cf316a5aa9077778a232e72da1d3b2b509ab ec1ddc8efa58f0aa76800bd5cb0209e118718e6c girmaat <girmaat@gmail.com> 1747854173 +0000	commit: yaml updated
ec1ddc8efa58f0aa76800bd5cb0209e118718e6c e6de54733422c66d18859882faa550ce5bf68c6f girmaat <girmaat@gmail.com> 1747869289 +0000	commit: Infra destroyed



43. .git/logs/refs/remotes/origin/main

0000000000000000000000000000000000000000 dc28cf316a5aa9077778a232e72da1d3b2b509ab girmaat <girmaat@gmail.com> 1747852770 +0000	update by push
dc28cf316a5aa9077778a232e72da1d3b2b509ab ec1ddc8efa58f0aa76800bd5cb0209e118718e6c girmaat <girmaat@gmail.com> 1747854175 +0000	update by push
ec1ddc8efa58f0aa76800bd5cb0209e118718e6c e6de54733422c66d18859882faa550ce5bf68c6f girmaat <girmaat@gmail.com> 1747869292 +0000	update by push



44. .git/FETCH_HEAD

ec1ddc8efa58f0aa76800bd5cb0209e118718e6c		branch 'main' of github.com:girmaat/eksctl-my-vote-cluster



45. .git/ORIG_HEAD

e6de54733422c66d18859882faa550ce5bf68c6f



46. scripts/generate_project_summary.sh

#!/bin/bash

# Script and output file config
OUTPUT_FILE="project_code_summary.txt"
SCRIPT_NAME=$(basename "$0")

# Reset output file
> "$OUTPUT_FILE"

# Initialize file counter
counter=1

# Find all regular files (not dirs or symlinks)
find . -type f ! -path "./$SCRIPT_NAME" ! -path "./$OUTPUT_FILE" | while read -r file; do
  # Skip files ignored by git
  if git check-ignore -q "$file"; then
    continue
  fi

  # Skip binary files (optional)
  if grep -qIl . "$file"; then
    echo "$counter. ${file#./}" >> "$OUTPUT_FILE"
    echo "" >> "$OUTPUT_FILE"
    cat "$file" >> "$OUTPUT_FILE"
    echo -e "\n\n" >> "$OUTPUT_FILE"
    ((counter++))
  fi
done

echo "âœ… Project summary written to: $OUTPUT_FILE"



47. scripts/fix-aws-time-skew.sh

#!/bin/bash
set -euo pipefail

BLUE='\033[1;34m'
GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

echo -e "${BLUE}ğŸ”§ Restarting chronyd...${NC}"
sudo systemctl restart chronyd

echo -e "${BLUE}â±ï¸ Forcing immediate time sync with 'chronyc makestep'...${NC}"
sudo chronyc makestep

echo -e "${BLUE}ğŸ” Checking new system time drift...${NC}"
chronyc tracking

echo -e "${BLUE}ğŸ” Verifying AWS credentials (sts get-caller-identity)...${NC}"
if aws sts get-caller-identity > /dev/null 2>&1; then
  echo -e "${GREEN}[âœ”] AWS credentials are now valid. Time is synced.${NC}"
else
  echo -e "${RED}[âœ˜] AWS authentication still failing. Check your credentials or session.${NC}"
  exit 1
fi



48. scripts/validate-cluster.sh

#!/bin/bash
set -euo pipefail

CLUSTER_NAME="my-vote-cluster"
AWS_REGION="us-east-1"
NAMESPACE="monitoring"
SERVICE_ACCOUNT="fluentbit"
SCRIPT_NAME=$(basename "$0")

PASS_COUNT=0
FAIL_COUNT=0

# Colors for formatting output
GREEN='\033[0;32m'
BLUE='\033[1;34m'
RED='\033[0;31m'
NC='\033[0m'

# Utility functions
print_header() { echo -e "\n${BLUE}=== [$SCRIPT_NAME] $1 ===${NC}"; }
print_success() { echo -e "${GREEN}[âœ”] $1${NC}"; ((PASS_COUNT++)); }
print_fail() { echo -e "${RED}[âœ˜] $1${NC}"; ((FAIL_COUNT++)); }

# 1. Check if the EKS cluster exists
print_header "1. EKS Cluster Check"
if eksctl get cluster --region "$AWS_REGION" | grep -q "$CLUSTER_NAME"; then
  print_success "Cluster $CLUSTER_NAME exists in region $AWS_REGION"
else
  print_fail "Cluster $CLUSTER_NAME not found"
fi

# 2. Ensure all nodes are Ready
print_header "2. Node Health Check"
if kubectl get nodes > /dev/null 2>&1; then
  READY=$(kubectl get nodes --no-headers | grep -c ' Ready')
  TOTAL=$(kubectl get nodes --no-headers | wc -l)
  [[ "$READY" -eq "$TOTAL" ]] && print_success "All $READY node(s) are Ready" || print_fail "$READY of $TOTAL node(s) are Ready"
else
  print_fail "kubectl get nodes failed"
fi

# 3. Check if aws-auth ConfigMap is present
print_header "3. aws-auth ConfigMap Check"
if kubectl get configmap aws-auth -n kube-system > /dev/null 2>&1; then
  print_success "aws-auth ConfigMap exists"
else
  print_fail "aws-auth ConfigMap missing"
fi

# 4. Confirm that OIDC issuer is configured
print_header "4. OIDC Issuer Check"
OIDC_URL=$(aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" \
  --query "cluster.identity.oidc.issuer" --output text 2>/dev/null)
if [[ "$OIDC_URL" == https://* ]]; then
  print_success "OIDC issuer URL is set: $OIDC_URL"
else
  print_fail "OIDC issuer URL missing"
fi

# 5. Run a pod to test internet connectivity (egress)
print_header "5. Test Pod Egress to Internet"
if kubectl run testcurl --image=radial/busyboxplus:curl -i --tty --rm --restart=Never -- curl -s https://www.google.com | grep -q "<html"; then
  print_success "Pods have internet access"
else
  print_fail "Pod cannot access internet (egress failure)"
fi

# 6. Check if FluentBit service account is IRSA-annotated
print_header "6. IRSA Annotation Check (Optional)"
if kubectl get sa "$SERVICE_ACCOUNT" -n "$NAMESPACE" -o jsonpath='{.metadata.annotations.eks\.amazonaws\.com/role-arn}' 2>/dev/null | grep -q 'arn:'; then
  print_success "IRSA annotation present on $SERVICE_ACCOUNT in $NAMESPACE"
else
  print_fail "IRSA annotation missing or not set yet"
fi

# Final result summary
print_header "ğŸ§ª Validation Summary"
echo -e "${BLUE}Passed: $PASS_COUNT${NC} | ${RED}Failed: $FAIL_COUNT${NC}"
[[ "$FAIL_COUNT" -eq 0 ]] && exit 0 || exit 1



49. scripts/destroy-cluster.sh

#!/bin/bash
set -euo pipefail

CLUSTER_NAME="my-vote-cluster"
AWS_REGION="us-east-1"
TAG_KEY="Project"
TAG_VALUE="my-vote"
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

SCRIPT_NAME=$(basename "$0")
GREEN='\033[0;32m'
BLUE='\033[1;34m'
RED='\033[0;31m'
NC='\033[0m'

print_header()  { echo -e "\n${BLUE}=== [$SCRIPT_NAME] $1 ===${NC}"; }
print_success() { echo -e "${GREEN}[âœ”] $1${NC}"; }
print_fail()    { echo -e "${RED}[âœ˜] $1${NC}"; }

confirm() {
  echo -e "${RED}âš ï¸  Are you sure you want to destroy the EKS cluster \"$CLUSTER_NAME\" and all associated resources? (yes/no)${NC}"
  read -r ans
  [[ "$ans" == "yes" ]] || { echo -e "${RED}Aborted.${NC}"; exit 1; }
}

confirm

# 1. Delete PDBs (to avoid eviction blocks)
print_header "1. Deleting PodDisruptionBudgets in kube-system"
PDBS=$(kubectl get pdb -n kube-system -o name 2>/dev/null || true)
if [[ -z "$PDBS" ]]; then
  print_success "No PDBs found in kube-system"
else
  for pdb in $PDBS; do
    kubectl delete "$pdb" -n kube-system || true
    echo "Deleted $pdb"
  done
  print_success "All kube-system PDBs deleted"
fi

# 2. Force drain all nodes
print_header "2. Draining all nodes (forcefully)"
NODES=$(kubectl get nodes -o name 2>/dev/null || true)
if [[ -z "$NODES" ]]; then
  echo "No nodes found or kubeconfig invalid. Skipping drain."
else
  for node in $NODES; do
    echo -e "${BLUE}ğŸ”„ Draining $node${NC}"
    kubectl drain "$node" --ignore-daemonsets --force --delete-emptydir-data --grace-period=0 || true
  done
  print_success "Node draining complete"
fi

# 3. Delete EKS cluster
print_header "3. Deleting EKS Cluster with eksctl"
if eksctl delete cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" ; then
  print_success "EKS cluster $CLUSTER_NAME deleted"
else
  print_fail "Cluster deletion failed"
  exit 1
fi

# 4. Delete ECR repos
print_header "4. Deleting ECR Repositories"
for repo in my-vote-vote my-vote-result my-vote-worker; do
  if aws ecr describe-repositories --repository-names "$repo" --region "$AWS_REGION" > /dev/null 2>&1; then
    aws ecr delete-repository --repository-name "$repo" --region "$AWS_REGION" --force
    print_success "Deleted ECR repo: $repo"
  else
    echo "ECR repo $repo not found"
  fi
done

# 5. Delete orphaned EBS volumes
print_header "5. Checking for orphaned EBS volumes"
VOLUMES=$(aws ec2 describe-volumes \
  --region "$AWS_REGION" \
  --filters "Name=tag:$TAG_KEY,Values=$TAG_VALUE" \
  --query "Volumes[*].VolumeId" --output text)

if [[ -z "$VOLUMES" ]]; then
  print_success "No orphaned EBS volumes"
else
  for vol in $VOLUMES; do
    aws ec2 delete-volume --volume-id "$vol" --region "$AWS_REGION"
    echo "Deleted volume $vol"
  done
fi

# 6. Release orphaned Elastic IPs
print_header "6. Releasing orphaned Elastic IPs"
EIPS=$(aws ec2 describe-addresses \
  --region "$AWS_REGION" \
  --filters "Name=tag:$TAG_KEY,Values=$TAG_VALUE" \
  --query "Addresses[*].AllocationId" --output text)

if [[ -z "$EIPS" ]]; then
  print_success "No orphaned Elastic IPs"
else
  for eip in $EIPS; do
    aws ec2 release-address --allocation-id "$eip" --region "$AWS_REGION"
    echo "Released EIP: $eip"
  done
fi

# 7. Delete IAM roles
print_header "7. IAM Role Cleanup"
ROLES=$(aws iam list-roles \
  --query "Roles[?contains(RoleName, \`eksctl-$CLUSTER_NAME\`)].RoleName" \
  --output text)

if [[ -z "$ROLES" ]]; then
  print_success "No leftover eksctl IAM roles"
else
  for role in $ROLES; do
    policies=$(aws iam list-attached-role-policies --role-name "$role" \
              --query 'AttachedPolicies[*].PolicyArn' --output text)
    for policy in $policies; do
      aws iam detach-role-policy --role-name "$role" --policy-arn "$policy"
    done
    aws iam delete-role --role-name "$role"
    echo "Deleted IAM role: $role"
  done
fi

# 8. Delete OIDC provider
print_header "8. Deleting OIDC Provider (if exists)"
OIDC_URL=$(aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" \
  --query "cluster.identity.oidc.issuer" --output text 2>/dev/null || true)

if [[ "$OIDC_URL" == https://* ]]; then
  OIDC_HOST=$(echo "$OIDC_URL" | cut -d/ -f3)
  PROVIDER_ARN="arn:aws:iam::$ACCOUNT_ID:oidc-provider/$OIDC_HOST"
  if aws iam get-open-id-connect-provider --open-id-connect-provider-arn "$PROVIDER_ARN" > /dev/null 2>&1; then
    aws iam delete-open-id-connect-provider --open-id-connect-provider-arn "$PROVIDER_ARN"
    print_success "Deleted OIDC provider: $PROVIDER_ARN"
  else
    echo "OIDC provider $PROVIDER_ARN not found"
  fi
else
  echo "OIDC URL not found or control plane already deleted"
fi

print_header "ğŸ§¹ Cluster Teardown Complete"



50. scripts/validate-destroy.sh

#!/bin/bash
set -euo pipefail
#set -x  # Uncomment for step-by-step trace

CLUSTER_NAME="my-vote-cluster"
AWS_REGION="us-east-1"
TAG_KEY="Project"
TAG_VALUE="my-vote"

SCRIPT_NAME=$(basename "$0")
PASS_COUNT=0
FAIL_COUNT=0

GREEN='\033[0;32m'
BLUE='\033[1;34m'
RED='\033[0;31m'
NC='\033[0m'

print_header()  { echo -e "\n${BLUE}=== [$SCRIPT_NAME] $1 ===${NC}"; }
print_success() { echo -e "${GREEN}[âœ”] $1${NC}"; ((PASS_COUNT++)); }
print_fail()    { echo -e "${RED}[âœ˜] $1${NC}"; ((FAIL_COUNT++)); }

# 0. Verify AWS credentials
print_header "0. Verifying AWS credentials"
if ! aws sts get-caller-identity > /dev/null 2>&1; then
  print_fail "AWS credentials invalid or expired"
  exit 1
else
  print_success "AWS credentials valid"
fi

# 0.1 Extract AWS Account ID safely
print_header "0.1 Extracting AWS Account ID"
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text 2>/dev/null || echo "")

if [[ -z "$ACCOUNT_ID" ]]; then
  print_fail "Failed to retrieve AWS Account ID (empty or command failed)"
  exit 1
else
  print_success "AWS Account ID is $ACCOUNT_ID"
  echo "[DEBUG] ACCOUNT_ID=$ACCOUNT_ID"
fi

# 1. EKS cluster check
print_header "1. EKS Cluster Deletion Check"
if aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" 2>/dev/null; then
  print_fail "EKS cluster \"$CLUSTER_NAME\" still exists"
else
  print_success "EKS cluster \"$CLUSTER_NAME\" is gone"
fi

# 2. VPC check
print_header "2. VPC Check (tagged $TAG_KEY=$TAG_VALUE)"
VPCS=$(aws ec2 describe-vpcs \
  --region "$AWS_REGION" \
  --filters "Name=tag:$TAG_KEY,Values=$TAG_VALUE" \
  --query "Vpcs[*].VpcId" --output text)

if [[ -z "$VPCS" ]]; then
  print_success "No tagged VPCs found"
else
  print_fail "Remaining VPC(s): $VPCS"
fi

# 3. EBS volume check
print_header "3. EBS Volume Check"
VOLUMES=$(aws ec2 describe-volumes \
  --region "$AWS_REGION" \
  --filters "Name=tag:$TAG_KEY,Values=$TAG_VALUE" \
  --query "Volumes[*].VolumeId" --output text)

if [[ -z "$VOLUMES" ]]; then
  print_success "No orphaned volumes found"
else
  print_fail "Found leftover volumes: $VOLUMES"
fi

# 4. Elastic IP check
print_header "4. Elastic IP Check"
EIPS=$(aws ec2 describe-addresses \
  --region "$AWS_REGION" \
  --filters "Name=tag:$TAG_KEY,Values=$TAG_VALUE" \
  --query "Addresses[*].PublicIp" --output text 2>/dev/null || echo "")

if [[ -z "$EIPS" ]]; then
  print_success "No orphaned Elastic IPs"
else
  print_fail "Found orphaned EIPs: $EIPS"
fi

# 5. IAM Role check
print_header "5. IAM Role Cleanup Check"
ROLES=$(aws iam list-roles \
  --query "Roles[?contains(RoleName, \`eksctl-$CLUSTER_NAME\`)].RoleName" \
  --output text)

if [[ -z "$ROLES" ]]; then
  print_success "No eksctl IAM roles remain"
else
  print_fail "Remaining IAM roles: $ROLES"
fi

# 6. OIDC Provider check
print_header "6. OIDC Provider Check"
OIDC_PROVIDERS=$(aws iam list-open-id-connect-providers \
  --query "OpenIDConnectProviderList[*].Arn" --output text)

OIDC_URL=$(aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" \
  --query "cluster.identity.oidc.issuer" --output text 2>/dev/null || true)

if [[ "$OIDC_URL" == https://* ]]; then
  OIDC_HOST=$(echo "$OIDC_URL" | cut -d/ -f3)
  EXPECTED_OIDC="arn:aws:iam::$ACCOUNT_ID:oidc-provider/$OIDC_HOST"
  if echo "$OIDC_PROVIDERS" | grep -q "$EXPECTED_OIDC"; then
    print_fail "OIDC provider still present: $EXPECTED_OIDC"
  else
    print_success "OIDC provider is gone"
  fi
else
  print_success "No OIDC URL found (control plane likely deleted)"
fi

# 7. ECR Repository check
print_header "7. ECR Repository Check"
ECR_REPOS=$(aws ecr describe-repositories --region "$AWS_REGION" \
  --query "repositories[*].repositoryName" --output text)

UNDELETED_REPOS=()
for repo in my-vote-vote my-vote-result my-vote-worker; do
  if echo "$ECR_REPOS" | grep -q "$repo"; then
    UNDELETED_REPOS+=("$repo")
  fi
done

if [[ ${#UNDELETED_REPOS[@]} -eq 0 ]]; then
  print_success "All ECR repos are deleted"
else
  print_fail "Remaining ECR repos: ${UNDELETED_REPOS[*]}"
fi

# âœ… Final Summary
print_header "ğŸ” Validation Summary"
echo -e "${BLUE}Passed: $PASS_COUNT${NC} | ${RED}Failed: $FAIL_COUNT${NC}"
[[ "$FAIL_COUNT" -eq 0 ]] && exit 0 || exit 1



51. scripts/patch-aws-auth.sh

#!/bin/bash
set -euo pipefail

CLUSTER_NAME="my-vote-cluster"
AWS_REGION="us-east-1"
SCRIPT_NAME=$(basename "$0")

BLUE='\033[1;34m'
GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

log()    { echo -e "${BLUE}ğŸ”· [$SCRIPT_NAME] $*${NC}"; }
ok()     { echo -e "${GREEN}âœ… $*${NC}"; }
error()  { echo -e "${RED}âŒ $*${NC}"; }

# Step 1: Get private DNS name of first node
log "Getting first node's internal DNS name..."
NODE_DNS=$(kubectl get nodes -o jsonpath='{.items[0].metadata.name}')

if [[ -z "$NODE_DNS" ]]; then
  error "No nodes found in the cluster"
  exit 1
fi

log "Node DNS: $NODE_DNS"

# Step 2: Lookup EC2 instance by private DNS
log "Finding EC2 instance for $NODE_DNS..."
INSTANCE_PROFILE_ARN=$(aws ec2 describe-instances \
  --region "$AWS_REGION" \
  --filters "Name=private-dns-name,Values=$NODE_DNS" \
  --query "Reservations[].Instances[].IamInstanceProfile.Arn" \
  --output text)

if [[ -z "$INSTANCE_PROFILE_ARN" ]]; then
  error "Failed to find instance profile for $NODE_DNS"
  exit 1
fi

INSTANCE_PROFILE_NAME=$(basename "$INSTANCE_PROFILE_ARN")
log "Instance profile: $INSTANCE_PROFILE_NAME"

# Step 3: Extract role ARN from instance profile
ROLE_ARN=$(aws iam get-instance-profile \
  --instance-profile-name "$INSTANCE_PROFILE_NAME" \
  --query "InstanceProfile.Roles[0].Arn" \
  --output text)

if [[ -z "$ROLE_ARN" ]]; then
  error "Failed to extract IAM role ARN from profile"
  exit 1
fi

log "IAM Role ARN: $ROLE_ARN"

# Step 4: Generate and apply aws-auth ConfigMap
log "Patching aws-auth ConfigMap..."

TMP_FILE=$(mktemp)
cat <<EOF > "$TMP_FILE"
apiVersion: v1
kind: ConfigMap
metadata:
  name: aws-auth
  namespace: kube-system
data:
  mapRoles: |
    - rolearn: $ROLE_ARN
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes
EOF

kubectl apply -f "$TMP_FILE"
rm -f "$TMP_FILE"
ok "aws-auth ConfigMap patched successfully!"



52. scripts/build-and-push.sh

#!/bin/bash

# Usage: ./build-and-push.sh <service_name>
# Example: ./build-and-push.sh vote

set -e

SERVICE_NAME=$1

if [ -z "$SERVICE_NAME" ]; then
  echo "Usage: $0 <service_name>"
  exit 1
fi

AWS_REGION="us-east-1"
AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
ECR_REPO="$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/my-vote-$SERVICE_NAME"

# Authenticate Docker to AWS ECR
aws ecr get-login-password --region "$AWS_REGION" | \
  docker login --username AWS --password-stdin "$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com"

# Build the Docker image
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
docker build -t "$ECR_REPO:latest" "$PROJECT_ROOT/manifests/$SERVICE_NAME"

# Push the image to ECR
docker push "$ECR_REPO:latest"



53. scripts/audit-eks-resources.sh

#!/bin/bash
set -euo pipefail

CLUSTER_NAME="my-vote-cluster"
AWS_REGION="us-east-1"
PROJECT_TAG_KEY="Project"
PROJECT_TAG_VALUE="my-vote"
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

ask_to_continue() {
  echo -n "ğŸ‘‰ Do you want to delete this manually now? (yes/no/skip all): "
  read -r choice
  case "$choice" in
    yes) return 0 ;;
    no)  return 1 ;;
    skip*) echo "âš ï¸  Skipping all further deletions."; exit 0 ;;
    *)    echo "Invalid input. Exiting."; exit 1 ;;
  esac
}

print_header() {
  echo -e "\n\033[1;34m=== Checking: $1 ===\033[0m"
}

# 1. EKS Cluster
print_header "EKS Cluster"
if aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" >/dev/null 2>&1; then
  echo "âŒ Cluster $CLUSTER_NAME still exists."
else
  echo "âœ… Cluster $CLUSTER_NAME is gone."
fi

# 2. VPCs tagged to project
print_header "VPCs tagged $PROJECT_TAG_KEY=$PROJECT_TAG_VALUE"
VPCS=$(aws ec2 describe-vpcs \
  --region "$AWS_REGION" \
  --filters "Name=tag:$PROJECT_TAG_KEY,Values=$PROJECT_TAG_VALUE" \
  --query "Vpcs[*].VpcId" --output text)

if [[ -z "$VPCS" ]]; then
  echo "âœ… No tagged VPCs found."
else
  echo "âŒ Found VPCs: $VPCS"
  ask_to_continue
fi

# 3. EBS Volumes
print_header "EBS Volumes tagged $PROJECT_TAG_KEY=$PROJECT_TAG_VALUE"
VOLUMES=$(aws ec2 describe-volumes \
  --region "$AWS_REGION" \
  --filters "Name=tag:$PROJECT_TAG_KEY,Values=$PROJECT_TAG_VALUE" \
  --query "Volumes[*].VolumeId" --output text)

if [[ -z "$VOLUMES" ]]; then
  echo "âœ… No orphaned volumes found."
else
  echo "âŒ Orphaned volumes: $VOLUMES"
  ask_to_continue
fi

# 4. Elastic IPs
print_header "Elastic IPs tagged $PROJECT_TAG_KEY=$PROJECT_TAG_VALUE"
EIPS=$(aws ec2 describe-addresses \
  --region "$AWS_REGION" \
  --filters "Name=tag:$PROJECT_TAG_KEY,Values=$PROJECT_TAG_VALUE" \
  --query "Addresses[*].AllocationId" --output text)

if [[ -z "$EIPS" ]]; then
  echo "âœ… No orphaned Elastic IPs."
else
  echo "âŒ Found orphaned EIPs: $EIPS"
  ask_to_continue
fi

# 5. IAM Roles
print_header "IAM Roles from eksctl for $CLUSTER_NAME"
ROLES=$(aws iam list-roles \
  --query "Roles[?contains(RoleName, \`eksctl-$CLUSTER_NAME\`)].RoleName" \
  --output text)

if [[ -z "$ROLES" ]]; then
  echo "âœ… No eksctl IAM roles remain."
else
  echo "âŒ Found roles: $ROLES"
  ask_to_continue
fi

# 6. OIDC Provider
print_header "OIDC Provider for $CLUSTER_NAME"
OIDC_HOST=$(aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" \
  --query "cluster.identity.oidc.issuer" --output text 2>/dev/null | cut -d/ -f3 || true)

if [[ -n "$OIDC_HOST" ]]; then
  OIDC_ARN="arn:aws:iam::$ACCOUNT_ID:oidc-provider/$OIDC_HOST"
  echo "âŒ OIDC provider still exists: $OIDC_ARN"
  ask_to_continue
else
  echo "âœ… No OIDC provider found."
fi

# 7. ECR Repositories
print_header "ECR Repositories (vote, result, worker)"
for repo in my-vote-vote my-vote-result my-vote-worker; do
  if aws ecr describe-repositories --repository-names "$repo" --region "$AWS_REGION" > /dev/null 2>&1; then
    echo "âŒ ECR repository exists: $repo"
    ask_to_continue
  else
    echo "âœ… ECR repo $repo is deleted."
  fi
done

# 8. eksctl CloudFormation Stacks
print_header "eksctl CloudFormation Stacks"
STACKS=$(aws cloudformation describe-stacks --region "$AWS_REGION" \
  --query "Stacks[?starts_with(StackName, 'eksctl-$CLUSTER_NAME')].StackName" --output text)

if [[ -z "$STACKS" ]]; then
  echo "âœ… No eksctl-related stacks found."
else
  echo "âŒ Found CloudFormation stacks: $STACKS"
  ask_to_continue
fi

echo -e "\n\033[0;32mğŸ‰ Manual audit complete.\033[0m"



54. envs/dev/ecr.tf

module "ecr_vote" {
  source = "../../modules/ecr"
  name   = "my-vote-vote"
  tags = {
    Cluster     = "my-vote-cluster"
    Project     = "my-vote"
    Environment = "dev"
    ManagedBy   = "Terraform"
  }
}

module "ecr_result" {
  source = "../../modules/ecr"
  name   = "my-vote-result"
  tags = {
    Cluster     = "my-vote-cluster"
    Project     = "my-vote"
    Environment = "dev"
    ManagedBy   = "Terraform"
  }
}

module "ecr_worker" {
  source = "../../modules/ecr"
  name   = "my-vote-worker"
  tags = {
    Cluster     = "my-vote-cluster"
    Project     = "my-vote"
    Environment = "dev"
    ManagedBy   = "Terraform"
  }
}



55. envs/dev/outputs.tf

output "ecr_vote_url" {
  value = module.ecr_vote.repository_url
}

output "ecr_result_url" {
  value = module.ecr_result.repository_url
}

output "ecr_worker_url" {
  value = module.ecr_worker.repository_url
}



56. modules/ecr/main.tf

resource "aws_ecr_repository" "this" {
  name                 = var.name
  image_tag_mutability = "MUTABLE"
  tags                 = var.tags

  lifecycle {
    prevent_destroy = false
  }
}



57. modules/ecr/variables.tf

variable "name" {
  type = string
}

variable "tags" {
  type    = map(string)
  default = {}
}



